{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitffbf114e69d1464681b07d0990c6001d",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game of Thrones - Battle Prediction\n",
    "Game of Thrones is a popular fantasy TV show based on a series of books written by George RR Martin.\n",
    "\n",
    "This notebook showcases the analysis and predictions of the battles in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from pandas_profiling import ProfileReport\n",
    "from IPython.display import display\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "rcParams['figure.figsize'] = 5, 6\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df = pd.read_csv('../../data/battles.csv')\n",
    "battles_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In reviewing the other kernels to see what has been done, [one particular kernel](https://www.kaggle.com/chrisbuetti/predicting-battle-outcomes-start-rmd) on Kaggle pointed out the data entry mistake on the Battle of Castle Rock. Having watched the TV series, I know for a fact that Mance Rayder has 100K wildings and Stannis Baratheon has 1,240 troops. I flipped the names in the dataset. This should be a major callout to anyone using this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Change `attacker_outcome` to boolean and fill nan with zeros for `major_death`,\t`major_capture`, `summer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attacker_outcome_flag'] = battles_df['attacker_outcome'].map({'win': 1, 'loss': 0})\n",
    "\n",
    "battles_df['attacker_outcome_flag'] = battles_df['attacker_outcome_flag'].fillna(0)\n",
    "battles_df['major_death'] = battles_df['major_death'].fillna(0)\n",
    "battles_df['major_capture'] = battles_df['major_capture'].fillna(0)\n",
    "battles_df['summer'] = battles_df['summer'].fillna(0)\n",
    "battles_df[['attacker_outcome','major_death','major_capture','summer']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run pandas profiler for fast EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(battles_df, title='Game of Thrones Battles - Pandas Profiling Report', style={'full_width':True})\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(output_file=\"got_battles_data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The columns `attacker_2`,`attacker_3`,`attacker_4`,`defender_2`,`defender_3`,`defender_4`, `attacker_commander`, `defender_commander` can be used to count the number of houses involved in the battle. \n",
    "\n",
    "Three columns will be created for:   \n",
    "\n",
    "* Number of attacking houses\n",
    "* Number of defending houses \n",
    "* Number of attacker_commander\t\n",
    "* Number of defender_commander\n",
    "* Battle Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attack_houses'] = battles_df[['attacker_1','attacker_2','attacker_3','attacker_4']].notnull().sum(axis=1)\n",
    "battles_df['attack_houses'] = pd.to_numeric(battles_df.attack_houses)\n",
    "\n",
    "battles_df['defender_houses'] = battles_df[['defender_1','defender_2','defender_3','defender_4']].notnull().sum(axis=1)\n",
    "battles_df['defender_houses'] = pd.to_numeric(battles_df.defender_houses)\n",
    "\n",
    "# Check data\n",
    "battles_df[['attacker_1','attacker_2','attacker_3','attacker_4','attack_houses','defender_1','defender_2','defender_3','defender_4','defender_houses']].sort_values(by=['attack_houses','defender_houses'],ascending=[False,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count occurence of `attacker_commander` and `defender_commander`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attacker_commander'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attacker_commander_count'] = battles_df['attacker_commander'].str.split(',', expand=True).notnull().sum(axis=1)\n",
    "battles_df[['attacker_commander','attacker_commander_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['defender_commander'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['defender_commander_count'] = battles_df['defender_commander'].str.split(',', expand=True).notnull().sum(axis=1)\n",
    "battles_df[['defender_commander','defender_commander_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop columns with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df = battles_df.drop(columns = ['battle_number','attacker_2','attacker_3','attacker_4','defender_2','defender_3','defender_4','note'])\n",
    "battles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create `battle_size` for the total number of people involved in a battle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['battle_size'] = battles_df['attacker_size'] + battles_df['defender_size']\n",
    "battles_df[['attacker_size','defender_size','battle_size']]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plot = battles_df.corr(method='pearson').style.set_caption('Correlation for Game of Thrones Battles').background_gradient(cmap='coolwarm').set_precision(4)\n",
    "corr_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run profiler again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(battles_df, title='Game of Thrones Battles - Pandas Profiling Report', style={'full_width':True})\n",
    "profile\n",
    "profile.to_file(output_file=\"got_battles_data_profile.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to clean battles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_battle_data(df):\n",
    "    df['attacker_outcome_flag'] = df['attacker_outcome'].map({'win': 1, 'loss': 0})\n",
    "\n",
    "    # Fill NaN with zero\n",
    "    df['attacker_outcome_flag'] = df['attacker_outcome_flag'].fillna(0)\n",
    "    df['major_death'] = df['major_death'].fillna(0)\n",
    "    df['major_capture'] = df['major_capture'].fillna(0)\n",
    "    df['summer'] = df['summer'].fillna(0)\n",
    "    df['attacker_size'] = df['attacker_size'].fillna(0)\n",
    "    df['defender_size'] = df['defender_size'].fillna(0)\n",
    "\n",
    "    # The columns attacker_2,attacker_3,attacker_4,defender_2,defender_3,defender_4, attacker_commander, defender_commander can be used to count the number of houses involved in the battle.\n",
    "    df['attack_houses'] = df[['attacker_1','attacker_2','attacker_3','attacker_4']].notnull().sum(axis=1)\n",
    "    df['attack_houses'] = pd.to_numeric(df.attack_houses)\n",
    "\n",
    "    df['defender_houses'] = df[['defender_1','defender_2','defender_3','defender_4']].notnull().sum(axis=1)\n",
    "    df['defender_houses'] = pd.to_numeric(df.defender_houses)\n",
    "\n",
    "    # Count attacker_commander\n",
    "    df['attacker_commander_count'] = df['attacker_commander'].str.split(',', expand=True).notnull().sum(axis=1)\n",
    "\n",
    "    # Count defender_commander\n",
    "    df['defender_commander_count'] = df['defender_commander'].str.split(',', expand=True).notnull().sum(axis=1)\n",
    "\n",
    "    # Drop columns with missing data\n",
    "    df = df.drop(columns = ['battle_number','attacker_2','attacker_3','attacker_4','defender_2','defender_3','defender_4','note'])\n",
    "\n",
    "    # Create battle_size columns\n",
    "    df['battle_size'] = df['attacker_size'] + df['defender_size']\n",
    "    df['battle_size'] = df['battle_size'].fillna(0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df = pd.read_csv('../../data/battles.csv')\n",
    "battles_df = clean_battle_data(battles_df)\n",
    "battles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df.to_csv('../../data/battles_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the Fast EDA (one dimension):\n",
    "\n",
    "**`attacker_outcome`**  \n",
    "32 battles out of 38 battles were won (84.2%).\n",
    "\n",
    "**`attacker_king`**  \n",
    "On the offense, Joffrey/Tommen Baratheon were the attacking kings 36.8% of the time (14 battles) while Mance Rayder was only the attacking king once (5.3%).\n",
    "\n",
    "**`defender_king`**  \n",
    "On the defense, Robb Stark has been attacked 36.8% of the times (14 battles) while Joffrey/Tommen Baratheon were second (34.2% or 13 battles). Renly Baratheon defended once (2.6%).\n",
    "\n",
    "**`battle_type`**  \n",
    "We can see that the most common `battle_type` is pitched battle, appearing 36.8% (14 times) while razing was only 5.3% (twice).\n",
    "\n",
    "**`region`**    \n",
    "Most of the battles were fought in The Riverlands (44.7% or 17 battles) while the second most battles fought were in The North (26.3% or 10 battles). There was only one battle Beyond The Wall (2.6%).\n",
    "\n",
    "**`summer`**  \n",
    "Most of the battles were fought in the summer (26 or 68.4%) while the remaing were fought in the winter (12 battles or 31.6%).\n",
    "\n",
    "**`year`**  \n",
    "Majority of the battles were fought in the year 299 (52.6% or 20 battles) and the second in the year 300 (28.9% or 11 battles). The remainder year 298 had only 7 battles (18.4%).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple dimensional view\n",
    "\n",
    "We will examine using multiple variables to see how they play together.\n",
    "\n",
    "* attacker_king vs attacker_outcome  \n",
    "* defender_king vs attacker_outcome  \n",
    "* battle_type vs attacker_outcome  \n",
    "* summer vs battle_type vs attacker_outcome  \n",
    "* battle_type vs attacker_king vs attacker_outcome  \n",
    "* battle_type vs defender_king vs attacker_outcome  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = battles_df.groupby(by=['attacker_king']).agg(\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'attacker_outcome_flag_count', ascending = False)\n",
    "\n",
    "df_grouped['attacker_outcome_loss'] = df_grouped['attacker_outcome_flag_count'] - df_grouped['attacker_outcome_wins']\n",
    "df_grouped['attacker_outcome_wins_pct'] = (df_grouped['attacker_outcome_wins']/df_grouped['attacker_outcome_flag_count']) * 100\n",
    "df_grouped['attacker_outcome_loss_pct'] = 100 - df_grouped['attacker_outcome_wins_pct']\n",
    "df_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[['attacker_king','attacker_outcome_wins_pct','attacker_outcome_loss_pct']].plot.bar(x='attacker_king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[['attacker_king','attacker_size_mean','defender_size_mean']].plot.bar(x='attacker_king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Mance Rayder\n",
    "df_grouped[['attacker_king','attacker_size_mean','defender_size_mean']][df_grouped.attacker_king != 'Mance Rayder'].plot.bar(x='attacker_king')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Battle year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = battles_df.groupby(by=['year']).agg(\n",
    "    battles = ('name','count'),\n",
    "    major_death = ('major_death', 'sum'),\n",
    "    major_capture = ('major_capture','sum')).reset_index().sort_values(by = 'year', ascending = True)\n",
    "    \n",
    "df_year.plot.bar(x='year')\n",
    "display(df_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Battle vs Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region = battles_df.groupby(by=['region']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    major_death = ('major_death', 'sum'),\n",
    "    major_capture = ('major_capture','sum')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "    \n",
    "df_region.plot.bar(x='region')\n",
    "display(df_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Battle_Type vs Kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battle_type = battles_df.groupby(by=['battle_type']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    major_death = ('major_death', 'sum'),\n",
    "    major_capture = ('major_capture','sum')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "    \n",
    "df_battle_type.plot.bar(x='battle_type')\n",
    "display(df_battle_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(battles_df['region']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(battles_df['battle_type']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(battles_df['attacker_1']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(battles_df['defender_1']).plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(battles_df['summer']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attacker_size'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['defender_size'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attack_houses'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['defender_houses'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['attacker_commander_count'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df['defender_commander_count'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## battle_type vs attacker_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battle_type = battles_df.groupby(by=['battle_type']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "\n",
    "df_battle_type['attacker_outcome_loss'] = df_battle_type['attacker_outcome_flag_count'] - df_battle_type['attacker_outcome_wins']\n",
    "df_battle_type['attacker_outcome_wins_pct'] = (df_battle_type['attacker_outcome_wins']/df_battle_type['attacker_outcome_flag_count']) * 100\n",
    "df_battle_type['attacker_outcome_loss_pct'] = 100 - df_battle_type['attacker_outcome_wins_pct']\n",
    "df_battle_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"battle_type\", y=\"attacker_outcome_wins_pct\",\n",
    "            aspect=0.8,\n",
    "            kind=\"bar\", data=df_battle_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summer vs battle_type vs attacker_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battle_type_summer = battles_df.groupby(by=['summer','battle_type','attacker_outcome']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "\n",
    "df_battle_type_summer['attacker_outcome_loss'] = df_battle_type_summer['attacker_outcome_flag_count'] - df_battle_type_summer['attacker_outcome_wins']\n",
    "df_battle_type_summer['attacker_outcome_wins_pct'] = (df_battle_type_summer['attacker_outcome_wins']/df_battle_type_summer['attacker_outcome_flag_count']) * 100\n",
    "df_battle_type_summer['attacker_outcome_loss_pct'] = 100 - df_battle_type_summer['attacker_outcome_wins_pct']\n",
    "df_battle_type_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"battle_type\", y=\"attacker_outcome_wins_pct\",\n",
    "            col=\"summer\", aspect=1,\n",
    "            kind=\"bar\", data=df_battle_type_summer)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## battle_type vs. attacker_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battle_attacker_king = battles_df.groupby(by=['attacker_king','battle_type']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "\n",
    "df_battle_attacker_king['attacker_outcome_loss'] = df_battle_attacker_king['attacker_outcome_flag_count'] - df_battle_attacker_king['attacker_outcome_wins']\n",
    "df_battle_attacker_king['attacker_outcome_wins_pct'] = (df_battle_attacker_king['attacker_outcome_wins']/df_battle_attacker_king['attacker_outcome_flag_count']) * 100\n",
    "df_battle_attacker_king['attacker_outcome_loss_pct'] = 100 - df_battle_attacker_king['attacker_outcome_wins_pct']\n",
    "df_battle_attacker_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.catplot(x=\"attacker_king\", y=\"attacker_outcome_wins_pct\",\n",
    "                       col=\"battle_type\", aspect=1,\n",
    "                       kind=\"bar\", data=df_battle_attacker_king)\n",
    "chart.set_xticklabels(rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## battle_type vs. defender_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battle_defender_king = battles_df.groupby(by=['defender_king','battle_type']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "\n",
    "df_battle_defender_king['attacker_outcome_loss'] = df_battle_defender_king['attacker_outcome_flag_count'] - df_battle_defender_king['attacker_outcome_wins']\n",
    "df_battle_defender_king['attacker_outcome_wins_pct'] = (df_battle_defender_king['attacker_outcome_wins']/df_battle_defender_king['attacker_outcome_flag_count']) * 100\n",
    "df_battle_defender_king['attacker_outcome_loss_pct'] = 100 - df_battle_defender_king['attacker_outcome_wins_pct']\n",
    "df_battle_defender_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.catplot(x=\"defender_king\", y=\"attacker_outcome_loss_pct\",\n",
    "                       col=\"battle_type\", aspect=1,\n",
    "                       kind=\"bar\", data=df_battle_defender_king)\n",
    "chart.set_xticklabels(rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attacker_king vs defender_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack_defend = battles_df.groupby(by=['attacker_king','defender_king']).agg(\n",
    "    battles_count = ('name','count'),\n",
    "    attacker_outcome_flag_count = ('attacker_outcome_flag','count'),\n",
    "    attacker_outcome_wins = ('attacker_outcome_flag','sum'),\n",
    "    attacker_size_mean = ('attacker_size', 'mean'),\n",
    "    defender_size_mean = ('defender_size','mean')).reset_index().sort_values(by = 'battles_count', ascending = False)\n",
    "\n",
    "df_attack_defend['attacker_outcome_loss'] = df_attack_defend['attacker_outcome_flag_count'] - df_attack_defend['attacker_outcome_wins']\n",
    "df_attack_defend['attacker_outcome_wins_pct'] = (df_attack_defend['attacker_outcome_wins']/df_attack_defend['attacker_outcome_flag_count']) * 100\n",
    "df_attack_defend['attacker_outcome_loss_pct'] = 100 - df_attack_defend['attacker_outcome_wins_pct']\n",
    "df_attack_defend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.catplot(x=\"attacker_king\", y=\"battles_count\",\n",
    "                       col=\"defender_king\", aspect=1,\n",
    "                       kind=\"bar\", data=df_attack_defend)\n",
    "chart.set_xticklabels(rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.catplot(x=\"attacker_king\", y=\"attacker_outcome_loss_pct\",\n",
    "                       col=\"defender_king\", aspect=1,\n",
    "                       kind=\"bar\", data=df_attack_defend)\n",
    "chart.set_xticklabels(rotation=45, horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.catplot(x=\"attacker_king\", y=\"attacker_outcome_wins_pct\",\n",
    "                       col=\"defender_king\", aspect=1,\n",
    "                       kind=\"bar\", data=df_attack_defend)\n",
    "chart.set_xticklabels(rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Battle Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.boxplot(x=\"attacker_king\", y=\"attacker_size\", data=battles_df[battles_df.attacker_king != 'Mance Rayder'], palette=\"Set1\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(),rotation=30)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.boxplot(x=\"attacker_king\", y=\"attacker_size\", data=battles_df[(battles_df.attacker_king != 'Mance Rayder') & (battles_df.attacker_outcome == 'win')], palette=\"Set1\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(),rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.boxplot(x=\"attacker_king\", y=\"attacker_size\", data=battles_df[(battles_df.attacker_king != 'Mance Rayder') & (battles_df.attacker_outcome == 'loss')], palette=\"Set1\")\n",
    "chart.set_xticklabels(chart.get_xticklabels(),rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Modeling Here\n",
    "\n",
    "There are two types of machine learning types that I will be performing:\n",
    "\n",
    "1) Regression Model for `attacker_size` vs 'defender_size` to determine the army size a house will be fighting against\n",
    "\n",
    "2) Classification Model - What factors determine the `attacker_outcome`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='attacker_size',y='defender_size',data=battles_df)\n",
    "display(battles_df[['attacker_size','defender_size']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "battles_df1 = battles_df[(battles_df.attacker_king != 'Mance Rayder') & (battles_df.attacker_size > 0) & (battles_df.defender_size > 0)]\n",
    "\n",
    "sns.lmplot(x='attacker_size', y='defender_size', data=battles_df1[['attacker_size','defender_size']],\n",
    "           robust=True, ci=None, scatter_kws={\"s\": 95})\n",
    "display(battles_df1[['attacker_size','defender_size']].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df1 = battles_df[(battles_df.attacker_king != 'Mance Rayder') & (battles_df.attacker_size > 0) & (battles_df.defender_size > 0)& (battles_df.attacker_size < 14000) & (battles_df.defender_size < 20000)]\n",
    "sns.lmplot(x='attacker_size', y='defender_size', data=battles_df1[['attacker_size','defender_size']],\n",
    "           robust=True, ci=None, scatter_kws={\"s\": 80})\n",
    "display(battles_df1[['attacker_size','defender_size']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df1 = battles_df[(battles_df.attacker_king != 'Mance Rayder') & (battles_df.attacker_outcome_flag == 1) & (battles_df.attacker_size > 0) & (battles_df.defender_size > 0) & (battles_df.attacker_size < 14000) & (battles_df.defender_size < 20000)]\n",
    "sns.lmplot(x='attacker_size', y='defender_size', data=battles_df1[['attacker_size','defender_size']],\n",
    "           robust=True, ci=None, scatter_kws={\"s\": 80})\n",
    "display(battles_df1[['attacker_size','defender_size']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Drop columns with missing data\n",
    "model_df = battles_df.drop(columns = ['name','location','attacker_commander','defender_commander','attacker_outcome','attacker_outcome_flag','battle_size'])\n",
    "attacker_outcome = battles_df['attacker_outcome_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[model_df.columns[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[model_df.columns[11:23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[['attacker_king','defender_king','attacker_1','defender_1']] = model_df[['attacker_king','defender_king','attacker_1','defender_1']].replace('/','_',regex=True)\n",
    "model_df[['attacker_king','defender_king','region','battle_type','attacker_1','defender_1']] = model_df[['attacker_king','defender_king','region','battle_type','attacker_1','defender_1']].replace(' ','_',regex=True)\n",
    "model_df[model_df.columns[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[model_df.columns[10:24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_mask = model_df.dtypes==object\n",
    "categorical_cols = model_df.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df1 = pd.get_dummies(model_df, columns=categorical_cols, prefix = categorical_cols)\n",
    "model_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log transform `defender_size` and `attacker_size`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['attacker_size', 'defender_size']\n",
    "features_log_transformed = pd.DataFrame(data = model_df1)\n",
    "features_log_transformed[skewed] = model_df1[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_log_transformed['attacker_size'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_log_transformed['defender_size'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attack_houses,defender_houses,attacker_commander_count,defender_commander_count,attacker_size,defender_size\n",
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['attack_houses','defender_houses','attacker_commander_count','defender_commander_count','attacker_size','defender_size']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = features_log_transformed\n",
    "features_final.to_csv('../../data/battles_data_model.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    attacker_outcome, \n",
    "                                                    random_state = 0,\n",
    "                                                    test_size = 0.25)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Selection\n",
    "\n",
    "* Logistic Regression  \n",
    "\n",
    "* Random Forest\n",
    "\n",
    "* XG Boost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 20)\n",
    "display(accuracies.mean())\n",
    "display(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The accuracy using logistic regression is 91.6% with a standard deviation of 0.2327 and we have a good baseline classification model already which is good news."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy',random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 20)\n",
    "display(accuracies.mean())\n",
    "display(accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the feature importances using .feature_importances_ \n",
    "importances = classifier.feature_importances_\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The accuracy using random forest is 95.0% with a standard deviation of 0.119. The accuracy improved by approximately 3.6% and the standard deviation decreased by almost half."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 20)\n",
    "display(accuracies.mean())\n",
    "display(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprisingly, XGBoost has the worst accuracy compared to the Logistic Regression and Random Forest models (90%) but it is still a good model.\n",
    "\n",
    "Random Forest has the best accuracy of 95%. The features importance are `attacker_size`, `attacker_commander_count`,`attack_houses`,`defender_size`, and `defender_houses`."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation - Extracting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy',random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 20)\n",
    "display(accuracies.mean())\n",
    "display(accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the feature importances using .feature_importances_ \n",
    "importances = classifier.feature_importances_\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = clf, X = X_train_reduced, y = y_train, cv = 20)\n",
    "display(accuracies.mean())\n",
    "display(accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "vs.feature_plot(importances, X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After we reduced the features down to the 5 most significant predictors, we get a slight improvement in accuracy of 96.6% and the standard deviation decreased slightly to 0.1. This is okay as we now have a model that can predict battle outcomes for Game of Thrones!\n",
    "\n",
    "The most important factors are:\n",
    "\n",
    "`attacker_size` - The size of the attacking house matter (unless you are Balon/Euron Greyjoy who wins with smaller armies)  \n",
    "`attacker_commander_count` - The count of the attacker commander matters as well.  \n",
    "`attack_houses`  - The number of attacking houses that are in the battle.  \n",
    "`defender_size`  - The size of the defender house matter (unless you are Balon/Euron Greyjoy who wins with smaller armies)  \n",
    "`defender_houses` - The number of defending houses that are in the battle.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}